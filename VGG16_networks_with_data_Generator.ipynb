{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG16 networks with data Generator.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/alamiin/VGG16/blob/master/VGG16_networks_with_data_Generator.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "nyUKtSt3h5cX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "c6eea79e-723b-4596-dca9-14a6ae027237"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xCG_oG_Vi4Ue",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "91fbc3c3-dc9e-40c5-c091-2a39f3e27711"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import time\n",
        "import h5py\n",
        "import csv\n",
        "from scipy import misc, ndimage\n",
        "from scipy.misc import imresize, imsave\n",
        "\n",
        "from sklearn.cross_validation import KFold, train_test_split\n",
        "from sklearn.metrics import log_loss, confusion_matrix\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "from PIL import Image, ImageChops, ImageOps\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "#os.environ['KERAS_BACKEND'] = 'theano'\n",
        "from keras import backend as K\n",
        "from keras.callbacks import EarlyStopping, Callback\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential, model_from_json\n",
        "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, Activation, Dropout, Flatten, Dense\n",
        "\n",
        "%matplotlib inline\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
            "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "hlrpOcRii5A6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_path =  \"/content/drive/My Drive/plamprint/database/database/\"\n",
        "weights_path = \"/content/drive/My Drive/Colab Notebooks/weight/vgg16_weights.h5\"\n",
        "bottleneck_model_weights_path = \"/content/drive/My Drive/Colab Notebooks/weight/bottleneck_weights.h5\"\n",
        "\n",
        "\n",
        "batch_size = 16\n",
        "nb_epoch = 50\n",
        "bottleneck_epoch = 3  \n",
        "val_split = .10  \n",
        "\n",
        "num_classes = 168\n",
        "img_width, img_height = 224, 224\n",
        "num_channels = 3\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YmrL-1vDj365",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gen = ImageDataGenerator( \n",
        "    rotation_range=20.,\n",
        "    fill_mode='constant',\n",
        "    data_format=\"channels_last\",\n",
        ")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IH_IEICMi5hc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_class_number(j):\n",
        "    \n",
        "    if(len(j.split(' '))==2):\n",
        "        return int(j.split(' ')[0].split('_')[1])\n",
        "    \n",
        "    else:\n",
        "        return int(j.split('(')[0].split('_')[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SBhj3PjojOb4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_COEP():\n",
        "    X_train = []\n",
        "    X_train_id = []\n",
        "    y_train = []\n",
        "    start_time = time.time()\n",
        "\n",
        "    print('Loading training images...')\n",
        "    \n",
        "    \n",
        "    for _, dirnames, filenames in os.walk(train_path):\n",
        "        all_dir.append(dirnames)\n",
        "\n",
        "\n",
        "    classs = []\n",
        "    label = []\n",
        "    \n",
        "    \n",
        "    i = 0\n",
        "    for _, dirnames, filenames in os.walk(train_path):\n",
        "        print(\"Totala number of Instance of COEP dataset: {}\".format(len(filenames)))\n",
        "        for j in filenames:\n",
        "            image = cv2.imread(dirt+j)\n",
        "            \n",
        "            roi=image[0:1200, 400:1600] \n",
        "            img_rotation = cv2.resize(roi, (img_width, img_height ))\n",
        "            hsv = cv2.cvtColor(img_rotation, cv2.COLOR_BGR2HSV)\n",
        "            lower_skin = np.array([0,20,70], dtype=np.uint8)\n",
        "            upper_skin = np.array([20,255,255], dtype=np.uint8)\n",
        "            mask = cv2.inRange(hsv, lower_skin, upper_skin)\n",
        "            image = img_rotation.copy()\n",
        "            image[np.where(mask==0)] = 0\n",
        "            \n",
        "           \n",
        "            image = np.expand_dims(image,0)\n",
        "            aug_iter = gen.flow(image)\n",
        "            aug_images = [next(aug_iter)[0].astype(np.uint8) for i in range(4)]\n",
        "            for img in aug_images:\n",
        "             \n",
        "              X_train.append(img)\n",
        "              label.append(get_class_number(j))\n",
        "            if i % 100 == 0:\n",
        "              print(\"{} Number image have read complete. Next image is reading\".format(i))\n",
        "            i += 1\n",
        "\n",
        "\n",
        "    \n",
        "    print('Training data load time: {} seconds'.format(round(time.time() - start_time, 2)))\n",
        "    return X_train, label, classs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1IukPQQijZ34",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def normalize_train_data():\n",
        "    train_data, train_target, train_id = load_COEP()\n",
        "   \n",
        "    train_data = np.array(train_data, dtype=np.uint8)\n",
        "    train_target = np.array(train_target, dtype=np.uint8)\n",
        "    \n",
        "\n",
        "    train_data = train_data.astype('float32')\n",
        "    train_data = train_data / 255\n",
        "    train_target = np_utils.to_categorical(train_target, 168)\n",
        "\n",
        "    print('Shape of training data:', train_data.shape)\n",
        "    return train_data, train_target, train_id"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7iz_HXnMjaQo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "09711a0d-5fa9-401a-e9f9-5bceebdb7b58"
      },
      "cell_type": "code",
      "source": [
        "train_data, train_target, train_id = normalize_train_data()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading training images...\n",
            "Totala number of Instance of COEP dataset: 1303\n",
            "0 Number image have read complete. Next image is reading\n",
            "100 Number image have read complete. Next image is reading\n",
            "200 Number image have read complete. Next image is reading\n",
            "300 Number image have read complete. Next image is reading\n",
            "400 Number image have read complete. Next image is reading\n",
            "500 Number image have read complete. Next image is reading\n",
            "600 Number image have read complete. Next image is reading\n",
            "700 Number image have read complete. Next image is reading\n",
            "800 Number image have read complete. Next image is reading\n",
            "900 Number image have read complete. Next image is reading\n",
            "1000 Number image have read complete. Next image is reading\n",
            "1100 Number image have read complete. Next image is reading\n",
            "1200 Number image have read complete. Next image is reading\n",
            "1300 Number image have read complete. Next image is reading\n",
            "Training data load time: 108.82 seconds\n",
            "Shape of training data: (5212, 250, 250, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fckF6T5Xjao5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def save_bottleneck_features():\n",
        "    datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    # build the VGG16 network\n",
        "    model = Sequential()\n",
        "    model.add(ZeroPadding2D((1, 1), input_shape=( img_width, img_height, 3)))\n",
        "\n",
        "    model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_1'))\n",
        "    model.add(ZeroPadding2D((1, 1)))\n",
        "    model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_2'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    model.add(ZeroPadding2D((1, 1)))\n",
        "    model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_1'))\n",
        "    model.add(ZeroPadding2D((1, 1)))\n",
        "    model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_2'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    model.add(ZeroPadding2D((1, 1)))\n",
        "    model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_1'))\n",
        "    model.add(ZeroPadding2D((1, 1)))\n",
        "    model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_2'))\n",
        "    model.add(ZeroPadding2D((1, 1)))\n",
        "    model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_3'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    model.add(ZeroPadding2D((1, 1)))\n",
        "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_1'))\n",
        "    model.add(ZeroPadding2D((1, 1)))\n",
        "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_2'))\n",
        "    model.add(ZeroPadding2D((1, 1)))\n",
        "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_3'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    model.add(ZeroPadding2D((1, 1)))\n",
        "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_1'))\n",
        "    model.add(ZeroPadding2D((1, 1)))\n",
        "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_2'))\n",
        "    model.add(ZeroPadding2D((1, 1)))\n",
        "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_3'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # load the weights of the VGG16 networks\n",
        "    f = h5py.File(weights_path)\n",
        "    for k in range(f.attrs['nb_layers']):\n",
        "        if k >= len(model.layers):\n",
        "            # we don't look at the last (fully-connected) layers in the savefile\n",
        "            break\n",
        "        g = f['layer_{}'.format(k)]\n",
        "        weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n",
        "        if np.array(weights).shape[0] > 0:\n",
        "            weights[0] = np.transpose(np.array(weights[0])[:, :, ::-1, ::-1], (2, 3, 1, 0))\n",
        "        model.layers[k].set_weights(weights)\n",
        "    f.close()\n",
        "    print('Model loaded.')\n",
        "    \n",
        "    # create validation split\n",
        "    X_train, X_valid, Y_train, Y_valid = train_test_split(train_data, train_target, test_size=val_split)\n",
        "\n",
        "    # create generator for train data\n",
        "    generator = datagen.flow(\n",
        "            X_train,\n",
        "            Y_train,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=False)\n",
        "    print(\"Start pridict generator...\")\n",
        "    # save train features to .npy file\n",
        "    bottleneck_features_train = model.predict_generator(generator)\n",
        "    np.save(open('bottleneck_features_train.npy', 'wb'), bottleneck_features_train)\n",
        "    print(\"shape of bottleneck_features_train {}\".format(bottleneck_features_train.shape))\n",
        "    # create generator for validation data\n",
        "    generator = datagen.flow(\n",
        "            X_valid,\n",
        "            Y_valid,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=False)\n",
        "    \n",
        "    # save validation features to .npy file\n",
        "    bottleneck_features_validation = model.predict_generator(generator )\n",
        "    np.save(open('bottleneck_features_validation.npy', 'wb'), bottleneck_features_validation)\n",
        "    print(\"shape of bottleneck_features_validation {}\".format(bottleneck_features_validation.shape))\n",
        "    return Y_train, Y_valid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-jDQP7mGQm06",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_bottleneck_model():\n",
        "    train_labels, validation_labels = save_bottleneck_features()\n",
        "\n",
        "    train_data = np.load(open('bottleneck_features_train.npy', 'rb'))\n",
        "    validation_data = np.load(open('bottleneck_features_validation.npy', 'rb'))\n",
        "    \n",
        "    print(train_data.shape)\n",
        "    print(train_labels.shape)\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "\n",
        "    model.fit(train_data,\n",
        "              train_labels,\n",
        "              nb_epoch=5,\n",
        "              #batch_size=batch_size,\n",
        "              #validation_data=(validation_data, validation_labels),\n",
        "              #callbacks=[early_stopping],\n",
        "              #verbose=2\n",
        "             )\n",
        "    \n",
        "    model.save_weights(bottleneck_model_weights_path)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HcrQkXTUhhHf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "329c7b38-1b39-4b49-a3fc-fc0734c133e0"
      },
      "cell_type": "code",
      "source": [
        "train_bottleneck_model() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", name=\"conv1_1\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", name=\"conv1_2\")`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", name=\"conv2_1\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", name=\"conv2_2\")`\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", name=\"conv3_1\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", name=\"conv3_2\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", name=\"conv3_3\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv4_1\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv4_2\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv4_3\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv5_1\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv5_2\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv5_3\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model loaded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Q00rk-P3hkpA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "    model = Sequential()\n",
        "    model.add(ZeroPadding2D((1, 1), input_shape=( img_width, img_height, 3)))\n",
        "\n",
        "    model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_1'))\n",
        "    model.add(ZeroPadding2D((1, 1)))\n",
        "    model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_2'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    model.add(ZeroPadding2D((1, 1)))\n",
        "    model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_1'))\n",
        "    model.add(ZeroPadding2D((1, 1)))\n",
        "    model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_2'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    model.add(ZeroPadding2D((1, 1)))\n",
        "    model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_1'))\n",
        "    model.add(ZeroPadding2D((1, 1)))\n",
        "    model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_2'))\n",
        "    model.add(ZeroPadding2D((1, 1)))\n",
        "    model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_3'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    model.add(ZeroPadding2D((1, 1)))\n",
        "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_1'))\n",
        "    model.add(ZeroPadding2D((1, 1)))\n",
        "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_2'))\n",
        "    model.add(ZeroPadding2D((1, 1)))\n",
        "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_3'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    model.add(ZeroPadding2D((1, 1)))\n",
        "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_1'))\n",
        "    model.add(ZeroPadding2D((1, 1)))\n",
        "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_2'))\n",
        "    model.add(ZeroPadding2D((1, 1)))\n",
        "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_3'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "    \n",
        "    # load the weights of the VGG16 networks\n",
        "    f = h5py.File(weights_path)\n",
        "    for k in range(f.attrs['nb_layers']):\n",
        "        if k >= len(model.layers):\n",
        "            # we don't look at the last (fully-connected) layers in the savefile\n",
        "            break\n",
        "        g = f['layer_{}'.format(k)]\n",
        "        weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n",
        "        if np.array(weights).shape[0] > 0:\n",
        "            weights[0] = np.transpose(np.array(weights[0])[:, :, ::-1, ::-1], (2, 3, 1, 0))\n",
        "        model.layers[k].set_weights(weights)\n",
        "    f.close()\n",
        "    \n",
        "    # build a classifier model to put on top of the convolutional model\n",
        "    bottleneck_model = Sequential()\n",
        "    bottleneck_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
        "    bottleneck_model.add(Dense(256, activation='relu'))\n",
        "    bottleneck_model.add(Dropout(0.5))\n",
        "    bottleneck_model.add(Dense(num_classes, activation='softmax'))\n",
        "    \n",
        "    # load weights from bottleneck model\n",
        "    bottleneck_model.load_weights(bottleneck_model_weights_path)\n",
        "\n",
        "    # add the model on top of the convolutional base\n",
        "    model.add(bottleneck_model)\n",
        "\n",
        "    # set the first 25 layers (up to the last conv block)\n",
        "    # to non-trainable (weights will not be updated)\n",
        "    for layer in model.layers[:25]:\n",
        "        layer.trainable = False\n",
        "        \n",
        "    # compile the model with a SGD/momentum optimizer\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
        "                  metrics=['accuracy'])\n",
        "    return model "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_qUbDL26hwIS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "X_train, X_valid, Y_train, Y_valid = train_test_split(train_data, train_target, test_size=val_split)\n",
        "model = build_model()\n",
        "history = model.fit(X_train,\n",
        "          Y_train,\n",
        "          nb_epoch=200,\n",
        "         # shuffle=True,\n",
        "          #verbose=1,\n",
        "          validation_data=(X_valid, Y_valid),\n",
        "          #callbacks=callbacks\n",
        "         )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yml6DZg7h-pZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(history.history.keys())\n",
        "#  \"Accuracy\"\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "# \"Loss\"\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8bFxXNH9L5Vz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z_l9hdLg3Wfk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}